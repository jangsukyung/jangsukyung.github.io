---
layout: single
title:  "두 평균에 대한 비교 공부를 Python으로..."
categories: Python
tag: [Python, Statistics, t-test]
toc: true
author_profile: true
sidebar:
    nav: "sidebar-category"
---

# 두 평균의 비교 Preview

- 두 평균의 비교는 실무에서 자주 쓰이는 테스트이기 때문에 잘 배우도록 한다.
- 하나의 모수에 대해 두 그룹의 값이 같은지 검정하는 것
    - 만약 가정을 충족하면 Independent Sample T-Test / 충족하지 못하면 Mann-Whitney Test or Welch Test를 사용한다.

## 데이터 불러오기

- 데이터를 불러오도록 한다.
- 데이터는 각 tutor의 클래스 별 학생들의 점수를 나열한 것이다.
    - Anastasia(N = 15) & Bernadette(N = 18)

```python
import pandas as pd
df = pd.read_csv("https://raw.githubusercontent.com/ethanweed/pythonbook/main/Data/harpo.csv")
```

a

## 두 개의 검정

- Student’s T-Test
    - 모수 검정: 엄격한 가정 적용
- Welch’s
    - 비모수 검정: 가정에 대한 유연

## 가정

- 독립된 관측치(Independent Observations)
    - 두 그룹의 관측값은 서로 특별한 관계가 없다.
- 정규성(Nomality)
    - 정규 분포를 따른다. 만약 Sample Size가 N > 30이면 고려하지 않아도 됨.
- 등분산성 가정
    - Levene’s 검정 위반 시, Welch TEST

## 등분산성 위배의 의미

- Homogeneity of variance
- 각 그룹의 분산은 동일하다. 현실적으로는 각 그룹의 분산이 동일하다는 것은 기대하기 어렵다.

```python
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import scipy.stats as stats

sigma = 1
mu = 0
sigma1 = 1
mu2 = 2
sigma2 = 1.45

x1 = np.linspace(mu1 - 4 * sigma, mu1 + 4 * sigma1, 100)
y1 = 100 * stats.norm.pdf(x1, mu1, sigma1)
x2 = np.linspace(mu2 - 4 * sigma, mu2 + 4 * sigma2, 100)
y2 = 100 * sigma.norm.pdf(x2, mu2, sigma2)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))

sns.lineplot(x = x1, y = y1, color = 'black', ax = ax1)

sns.lineplot(x = x1, y = y1, color = 'black', ax = ax2)
sns.lineplot(x = x2, y = y2, color = 'black', ax = ax2)

ax1.text(0, 47, 'null hypothesis', size = 20, ha = 'center')
ax2.text(0, 47, 'alternative hypothesis', size = 20, ha = 'center')

ax1.text(0, 41, r'$\mu$', size = 20, ha = 'center')
ax2.text(0, 41, r'$\mu_1$', size = 20, ha = 'center')
ax2.text(1.50, 30, r'\mu_2$', size = 20, ha = 'center')

ax1.set_frame_on(False)
ax2.set_frame_on(False)
ax1.get_yaxis().set_visible(False)
ax2.get_yaxis().set_visible(False)
ax1.get_xaxis().set_visible(False)
ax2.get_xaxis().set_visible(False)
ax1.axhline(y = 0, color = 'black')
ax2.axhline(y = 0, color = 'black')
```

![평균1](https://user-images.githubusercontent.com/130429032/234798884-18fceb04-fc24-4e74-9ab2-482665ecb64e.png)

## 가설

- 귀무가설: 두 그룹의 평균은 같다.
- 대립가설: 두 그룹의 평균은 같지 않다.
- 이를 시각적으로 비교하면 아래와 같이 표현된다.

## 데이터 가공

- 기존 데이터의 Long 형태의 테이블에서 Wide 형태의 테이블로 변경해야 한다.

```python
wide_df = pd.pivot(df, columns = 'tutor', values = 'grade')
```

a

## 테스트

- NaN은 숫자가 아님의 약자이다.
- 별도로 처리해야 하지만, ttest()는 이를 적절하게 처리할 수 있는 기능이 있다.

- t-test

```python
from pingouin import ttest
ttest(wide_df['Anastasia'], wide_df['Bernadette'], correction = False)
```

![평균2](https://user-images.githubusercontent.com/130429032/234798889-3a13752c-8234-4158-a2d5-98e2c1ac7e67.png)

- levene test
    - 귀무가설: 두 그룹의 분산은 같음
    - 대립가설: 두 그룹의 분산은 다
- 테스트 결과 p.val 0.15 이므로 귀무가설을 채택한다. 즉, 두 그룹의 분산은 같다고 본다.

```python
from pingouin import homoscedasticity

homoscedasticity(data = df, dv = 'grade', group = 'tutor')
```

![평균3](https://user-images.githubusercontent.com/130429032/234798893-d8d86ee0-f2fa-4a1e-b13a-0f0418461305.png)

- Welch Test
    - 여기에서 사실 Welch Test 를 사용할 필요는 없다. 그러나, 한 번 사용하도록 한다.

```python
from pingouin import ttest
ttest(wide_df['Anastasia'], wide_df['Bernadette'], correction = True)
```

![평균4](https://user-images.githubusercontent.com/130429032/234798907-91cec84d-8894-44a8-b967-fc81d7da7b24.png)

- correction = True가 의미하는 것은 실제로 Welch Test를 수행하라는 말이다.
- 결과 보고서는 아래와 같이 작성할 수 있다.
    - Anastasia’s 클래스의 평균 점수는 74.5점이고 (std dev = 9.0), 반면에 Bernadette 클래스의 평균 점수는 69.1이고 (std dev = 5.8)이다. 독립 평균 샘플 t-test 결과 약 5.4 차이가 유의미하게 다르게 나타낸다. (t(31) = 2.1, p < 0.05)